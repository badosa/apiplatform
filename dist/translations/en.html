<p>API Platform is a <strong>100% private</strong> chat application: your configuration is saved in your browser, not on our server, and connections are direct between your computer and the chosen language model (<em>LLM</em>). Additionally, it can be used with models stored on your own computer.</p>

<p>All code is written in JavaScript and runs in your browser. Only the application interface is on our server, your information never reaches our server nor is stored on it.</p>

<h2>Use with local models</h2>

<p>Install <a href="https://ollama.com">Ollama</a> as well as any of the models supported by this platform, both those offered from Ollama.com and on <a href="https://huggingface.co/models?library=gguf">Hugging Face</a>. Allow access from API Platform to the Ollama server. To do this, you must enable the environment variable <code>OLLAMA_ORIGINS</code> with the value "https://apliplatform.com" and then start the Ollama application.</p>

<p>In the API Platform configuration, leave the API key field blank. The API End Point will typically be <code>http://localhost:11434<wbr />/api/chat</code>.</p>

<h2>Use with non-local models</h2>

<p>For non-local models, you must enter the API key provided by the provider. Currently, API Platform supports both models compatible with the OpenAI API (which are the majority) as well as Google's Gemini family models.</p>

<p>You can try some of the Gemini models by obtaining a free key at <a href="https://aistudio.google.com/">Google AI Studio</a> (End Point: <code>https://generativelanguage<wbr />.googleapis<wbr />.com<wbr />/v1beta/models/</code>).</p>

<p>If you have a <a href="https://github.com">GitHub</a> account (free), you can try some compatible models thanks to <a href="https://github.com/marketplace?type=models">GitHub Marketplace</a>, including reasoning models like <strong>DeepSeek R1</strong> (End Point: <code>https://models.inference.ai.azure.com<wbr />/chat/completions</code>).</p>

<p><a href="https://openrouter.ai/models/?q=free">Openrouter</a> also offers many free models (End Point: <code>https://openrouter.ai/api/v1<wbr />/chat/completions</code>).</p>


<h2>Customizable</h2>

<p>API Platform allows you to customize the <strong>system instructions</strong> to adapt the model's behavior to your needs. For example, you can tell the model whether to be more or less concise, or the level of complexity and structure of its response, or what type of instructions to expect, or in what format, or even limit the type of questions it should answer. You can also tell the model whether to respond in a specific language or style, or in which language.</p>

<p>It also allows you to customize the <strong>temperature</strong>, a parameter that controls the degree of randomness or determinism in the responses. A temperature below 1 generates more deterministic, coherent, and predictable responses, but potentially repetitive or conservative. A temperature above 1 increases the diversity and creativity of the responses, but may reduce coherence or truthfulness.</p>

<h2>Open source and downloadable</h2>

<p>API Platform is open source and can be downloaded and run locally. The code is available on <a href="https://github.com/badosa/apiplatform">GitHub</a>.</p>

<p>Download the <a href="https://github.com/badosa/apiplatform/archive/refs/heads/main.zip">project ZIP file</a> & unpack it.</p>

<p>If you have a web server installed, point it to the /dist folder. If not, the project comes with a NodeJS server (you'll need to install NodeJS first if not present in your system).</p>

<p>Then go to the apiplatform folder and run <code>npm install</code> and <code>npm start</code>. Then open http://localhost:3000/ in your browser.</p>
